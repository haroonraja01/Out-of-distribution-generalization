{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e1563cef-bed8-4a95-b627-5929571e97c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "from logging import getLogger\n",
    "import warnings\n",
    "\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import yaml \n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data as data\n",
    "import torch.distributed as dist\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167aa0ef-bdbc-49b6-a33c-b4954d674f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../src')) # or the path to your source code\n",
    "sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441ec94d-90d4-47c4-a832-319cda5febf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import (\n",
    "\tbool_flag,\n",
    "\tinitialize_exp,\n",
    "\trestart_from_checkpoint,\n",
    "\tfix_random_seeds,\n",
    "\tAverageMeter,\n",
    "\tinit_distributed_mode,\n",
    "\taccuracy,\n",
    "\tadd_slurm_params,\n",
    "\tget_dataloader,\n",
    "\toptimizer_config,\n",
    ")\n",
    "\n",
    "from models import get_model, get_classifier, modelfusion\n",
    "from datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ae33a9e1-52dd-45d1-b0db-a051b807c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, reglog, optimizer, loader,  epoch, args ):\n",
    "\t\"\"\"\n",
    "\tTrain the models on the dataset.\n",
    "\t\"\"\"\n",
    "\t# running statistics\n",
    "\tbatch_time = AverageMeter()\n",
    "\tdata_time = AverageMeter()\n",
    "\n",
    "\t# training statistics\n",
    "\ttop1 = AverageMeter()\n",
    "\ttop5 = AverageMeter()\n",
    "\tlosses = AverageMeter()\n",
    "\tend = time.perf_counter()\n",
    "\t\n",
    "\tmodel.eval()\n",
    "\treglog.train()\n",
    "\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\tfor iter_epoch, record in enumerate(loader):\n",
    "\t\t# measure data loading time\n",
    "\t\tdata_time.update(time.perf_counter() - end)\n",
    "\t\t\n",
    "\n",
    "\t\tif len(record) == 2:\n",
    "\t\t\tinp, target = record \n",
    "\t\telif len(record) == 3:\n",
    "\t\t\n",
    "\t\t\tinp, target, meta = record \n",
    "\t\t\n",
    "\t\t#move to gpu\n",
    "        # commenting next two lines for running on a cpu\n",
    "\t\t#inp = inp.cuda(non_blocking=True)\n",
    "\t\t#target = target.cuda(non_blocking=True)\n",
    "\t\t# forward\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutput = model(inp)\n",
    "\n",
    "\t\toutput = reglog(output)\n",
    "\t\tloss = criterion(output, target) \n",
    "\n",
    "\t\t# compute the gradients\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\t# update stats\n",
    "\t\tacc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\t\tlosses.update(loss.item(), inp.size(0))\n",
    "\t\ttop1.update(acc1[0], inp.size(0))\n",
    "\t\ttop5.update(acc5[0], inp.size(0))\n",
    "\n",
    "\t\tbatch_time.update(time.perf_counter() - end)\n",
    "\t\tend = time.perf_counter()\n",
    "\n",
    "\t\t# verbose\n",
    "\t\tif args.rank == 0 and iter_epoch % 50 == 0:\n",
    "\t\t\t\n",
    "\t\t\tlogger.info(\n",
    "\t\t\t\t\"Epoch[{0}] - Iter: [{1}/{2}]\\t\"\n",
    "\t\t\t\t\"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "\t\t\t\t\"Data {data_time.val:.3f} ({data_time.avg:.3f})\\t\"\n",
    "\t\t\t\t\"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
    "\t\t\t\t\"Prec {top1.val:.3f} ({top1.avg:.3f})\\t\"\n",
    "\t\t\t\t\"LR {lr}\".format(\n",
    "\t\t\t\t\tepoch,\n",
    "\t\t\t\t\titer_epoch,\n",
    "\t\t\t\t\tlen(loader),\n",
    "\t\t\t\t\tbatch_time=batch_time,\n",
    "\t\t\t\t\tdata_time=data_time,\n",
    "\t\t\t\t\tloss=losses,\n",
    "\t\t\t\t\ttop1=top1,\n",
    "\t\t\t\t\tlr=optimizer.param_groups[0][\"lr\"],\n",
    "\t\t\t\t)\n",
    "\t\t\t)\n",
    "\n",
    "\treturn epoch, losses.avg, top1.avg.item(), top5.avg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64e5677c-9dc5-466b-85fa-476ab4f90b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_network(val_loader, model, classifier, args, indices=None):\n",
    "\tbatch_time = AverageMeter()\n",
    "\tlosses = AverageMeter()\n",
    "\ttop1 = AverageMeter()\n",
    "\ttop5 = AverageMeter()\n",
    "\t#global best_acc\n",
    "\n",
    "\t# switch to evaluate mode\n",
    "\tmodel.eval()\n",
    "\tclassifier.eval()\n",
    "\n",
    "\tcriterion = nn.CrossEntropyLoss().cuda()\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tend = time.perf_counter()\n",
    "\t\tfor i, record in enumerate(val_loader):\n",
    "\t\t\tif len(record) == 2:\n",
    "\t\t\t\tinp, target = record \n",
    "\t\t\telif len(record) == 3:\n",
    "\t\t\t\tinp, target, meta = record \n",
    "\t\t\t\n",
    "\t\t\t# move to gpu\n",
    "\t\t\t#inp = inp.cuda(non_blocking=True)\n",
    "\t\t\t#target = target.cuda(non_blocking=True)\n",
    "\n",
    "\t\t\t# compute output\n",
    "\t\t\toutput = classifier(model(inp))\n",
    "\t\t\t\n",
    "\t\n",
    "\n",
    "\n",
    "\t\t\tif indices is not None:\n",
    "\t\t\t\toutput = output[:,indices]\n",
    "\n",
    "\t\t\tloss = criterion(output, target)\n",
    "\t\n",
    "\t\t\tacc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "\t\t\tlosses.update(loss.item(), inp.size(0))\n",
    "\n",
    "\t\t\ttop1.update(acc1[0], inp.size(0))\n",
    "\t\t\ttop5.update(acc5[0], inp.size(0))\n",
    "\n",
    "\t\t\t# measure elapsed time\n",
    "\t\t\tbatch_time.update(time.perf_counter() - end)\n",
    "\t\t\tend = time.perf_counter()\n",
    "\t\t\tif args.rank == 0 and i % 50 == 0:\n",
    "\t\t\t\tlogger.info(\n",
    "\t\t\t\t\"Epoch[{0}] - Iter: [{1}/{2}]\\t\"\n",
    "\t\t\t\t\"Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "\t\t\t\t\"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
    "\t\t\t\t\"Prec {top1.val:.3f} ({top1.avg:.3f})\\t\".format(\n",
    "\t\t\t\t\t0,\n",
    "\t\t\t\t\ti,\n",
    "\t\t\t\t\tlen(val_loader),\n",
    "\t\t\t\t\tbatch_time=batch_time,\n",
    "\t\t\t\t\tloss=losses,\n",
    "\t\t\t\t\ttop1=top1,\n",
    "\t\t\t\t)\n",
    "\t\t\t\t)\n",
    "\n",
    "\tscores_val = torch.Tensor(np.array([losses.sum, top1.sum.item(), top5.sum.item(), \\\n",
    "\t\t\t\t\t\t\t\tlosses.count, top1.count, top5.count])).to(target.get_device())\n",
    "\tdist.all_reduce(scores_val, op=dist.ReduceOp.SUM)\n",
    "\tscores_val = tuple((scores_val[:3] / scores_val[3:]).detach().cpu().numpy().tolist())\n",
    "\tlosses, top1, top5  = scores_val\n",
    "\treturn losses, top1, top5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "aa6e39b2-ceb2-4d62-b53f-5f509311112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    global best_acc\n",
    "    tags = yaml.load(open('../configs/pretrained_checkpoints.yaml'), Loader=yaml.FullLoader)\n",
    "    \n",
    "    if args.tag is not None and args.tag in tags:\n",
    "        for key in tags[args.tag]:\n",
    "            print(key)\n",
    "            setattr(args, key, tags[args.tag][key])\n",
    "    fix_random_seeds(args.seed)\n",
    "    # distributed training environments and seeds\n",
    "\t#init_distributed_mode(args)\n",
    "\t\n",
    "\t# amd gpu cards environment variables\n",
    "\t# os.environ['MIOPEN_USER_DB_PATH']=os.path.join(args.dump_path, 'amd/rank_%d' % args.rank)\n",
    "\t# os.environ['MIOPEN_FIND_MODE']='2'\n",
    "\n",
    "\t# initialize logger ...\n",
    "    logger, training_stats = initialize_exp( args, \"epoch\", \"loss\", \"prec1\", \"prec5\", \"loss_val\", \"prec1_val\", \"prec5_val\")\n",
    "\n",
    "\t# build data\n",
    "    #train_dataset, val_dataset, datamsg = get_dataset(args.data_name, args.tf_name, args)\n",
    "    # build dataloaders \n",
    "    # Commenting out dataloader for distributed\n",
    "    #train_loader, val_loader, additional_loaders = get_dataloader(train_dataset, val_dataset, datamsg, args)\n",
    "    transform = {\n",
    "    'train': transforms.Compose([transforms.Resize(255),\n",
    "                                 transforms.RandomRotation(30),\n",
    "                                 transforms.RandomResizedCrop(224),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                      [0.5, 0.5, 0.5])]),\n",
    "    'val': transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "    }\n",
    "\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(os.path.join(args.data_path, 'train'), transform=transform['train'])\n",
    "    val_dataset = datasets.ImageFolder(os.path.join(args.data_path, 'val'), transform=transform['val'])\n",
    "    datamsg = {'nclass': 2, 'img_dim': 224}\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    logger.info(\"Building data done\")\n",
    "\t## build trunk and load weights \n",
    "    total_feat_dim, feat_dims, models_new = 0, [], []\n",
    "    for i in range(len(args.arch)):\n",
    "        # HR: Commenting out following way of defining model, may need this later\n",
    "  #       per_model, msg, feat_dim = get_model(args.arch[i], skip_pool=args.skip_pool, \\\n",
    "\t\t# pretrain_path = None if len(args.pretrained)==0 else args.pretrained[i], img_dim=datamsg['img_dim'])\n",
    "        per_model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "        feat_dim = per_model.fc.in_features\n",
    "        msg = None\n",
    "\t\t#fix1st_pretrain_path = args.fix1st_pretrained ) #e.g. 'regnet_y_32gf'\n",
    "        logger.info(\"Load pretrained model with msg: {}\".format(msg))\n",
    "        feat_dims.append(feat_dim)\n",
    "        models_new.append(per_model)\n",
    "\t#build classifier\n",
    "    classifier = get_classifier(args.classifier, datamsg['nclass'], feat_dims, logger, args)\n",
    "\t#print(classifier.linear.weight.data)\n",
    "    logger.info('classifier {}'.format(classifier))\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    # model to gpu\n",
    "    # device = torch.device(\"cuda:\" + str(args.gpu_to_work_on))\n",
    "    # Using cpu for now\n",
    "\t# model is either Identity or backbone. only classifier is trainable\n",
    "    model, classifier = modelfusion(args.richway, models_new, classifier, args)\n",
    "    model, classifier = model.to(device), classifier.to(device)\n",
    "    # For distributed usage in future\n",
    "\t# classifier = nn.parallel.DistributedDataParallel(\n",
    "\t# \tclassifier,\n",
    "\t# \tdevice_ids=[args.gpu_to_work_on],\n",
    "\t# )\n",
    "    optimizer = optimizer_config(classifier, args, logger, \\\n",
    "\t\thead_reg = lambda x: True if args.exp_mode in ['lineareval','biaslineareval'] else lambda x: 'classifier' in x )\n",
    "    logger.info('optimizer {}'.format(optimizer))\n",
    "\t# set scheduler\n",
    "    if args.scheduler_type == \"step\":\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "\t\t\toptimizer, args.decay_epochs, gamma=args.gamma\n",
    "\t\t)\n",
    "    elif args.scheduler_type == \"cosine\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "\t\t\toptimizer, args.epochs, eta_min=args.final_lr)    \n",
    "    logger.info('lr scheduler {}'.format(scheduler))\n",
    "\t# Optionally resume from a checkpoint\n",
    "    to_restore = {\"epoch\": 0, \"best_acc\": 0.}\n",
    "    if 'save' in args.mode:\n",
    "        restart_from_checkpoint(\n",
    "\t\tos.path.join(args.dump_path, \"checkpoint.pth.tar\"),\n",
    "\t\trun_variables=to_restore,\n",
    "\t\tstate_dict=classifier,\n",
    "\t\t)\n",
    "        start_epoch = to_restore[\"epoch\"]\n",
    "        best_acc = to_restore[\"best_acc\"]\n",
    "    else:\n",
    "        restart_from_checkpoint(\n",
    "            os.path.join(args.dump_path, \"checkpoint.pth.tar\"), run_variables=to_restore, state_dict=classifier,\n",
    "            optimizer=optimizer,scheduler=scheduler,)\n",
    "        start_epoch = to_restore['epoch']\n",
    "        best_acc = to_restore[\"best_acc\"]\n",
    "    #cudnn.benchmark = True\n",
    "    eval('setattr(torch.backends.cudnn, \"benchmark\", True)')\n",
    "    \n",
    "    if args.cuda_deterministic:\n",
    "        logger.info(\"cuda deterministic\")\n",
    "        eval('setattr(torch.backends.cudnn, \"deterministic\", True)')\n",
    "    \n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        if epoch == 0 and args.save_init:\n",
    "            save_dict = {\n",
    "\t\t\t\t\t\"epoch\": 0,\n",
    "\t\t\t\t\t\"state_dict\": classifier.state_dict(),\n",
    "\t\t\t\t\t\"optimizer\": optimizer.state_dict(),\n",
    "\t\t\t\t\t\"scheduler\": scheduler.state_dict(),\n",
    "\t\t\t\t\t\"best_acc\": 0,\n",
    "\t\t\t\t}\n",
    "            torch.save(save_dict, os.path.join(args.dump_path, f\"checkpoint_init.pth.tar\"))\n",
    "            logger.info('saved weight initialization')\n",
    "        # train the network for one epoch\n",
    "        logger.info(\"============ Starting epoch %i ... ============\" % epoch)\n",
    "\n",
    "\t\t# set samplers\n",
    "        #train_loader.sampler.set_epoch(epoch)\n",
    "        tr_epoch, tr_loss, tr_top1, tr_top5 = train(model, classifier, optimizer, train_loader, epoch, args)\n",
    "        scheduler.step()\n",
    "        if (epoch+1) % args.eval_freq == 0:\n",
    "            loss, top1, top5 = validate_network(val_loader, model,  classifier, args,)\n",
    "            if args.custom_eval_func is not None:\n",
    "                from src import custom_eval\n",
    "                for custom_eval_name in args.custom_eval_func:\n",
    "                    custom_eval_func = getattr(custom_eval, custom_eval_name)\n",
    "                    custom_eval_results = custom_eval_func(val_loader, model, classifier, args)\n",
    "                    logger.info(f'{custom_eval_name}: ' + ','.join(['%.4f' % val for val in custom_eval_results]))\n",
    "            # additional validation sets\n",
    "            additional_msg = {}\n",
    "            for key in additional_loaders:\n",
    "                loader = additional_loaders[key]\n",
    "                ad_loss, ad_top1, ad_top5 = validate_network(loader, model,  classifier,args)\n",
    "                additional_msg[key]=[ad_loss, ad_top1, ad_top5]\n",
    "            training_stats.update([tr_epoch, tr_loss, tr_top1, tr_top5] + [loss, top1, top5])\n",
    "            is_best = False \n",
    "\t\t\t# log best acc\n",
    "\t\t\t#global best_acc\n",
    "            if top1 > best_acc:\n",
    "\t\t\t\t#best_acc = top1.avg.item()\n",
    "                best_acc = top1\n",
    "                is_best = True\n",
    "            if args.rank == 0:\n",
    "                logger.info(\n",
    "\t\t\t\t\t\"Test:\\t\"\n",
    "\t\t\t\t\t\"Loss {loss:.4f}\\t\"\n",
    "\t\t\t\t\t\"Acc@1 {top1:.3f}\\t\"\n",
    "\t\t\t\t\t\"Best Acc@1 so far {acc:.1f}\".format(loss=loss, top1=top1, acc=best_acc))\n",
    "                for key in additional_msg:\n",
    "                    loss, top1, _ = additional_msg[key]\n",
    "                    logger.info(\n",
    "\t\t\t\t\t\t\"additional Test {key}:\\t\"\n",
    "\t\t\t\t\t\t\"Loss {loss:.4f}\\t\"\n",
    "\t\t\t\t\t\t\"Acc@1 {top1:.3f}\".format(key=key, loss=loss, top1=top1))\n",
    "            if args.rank == 0:\n",
    "                # save checkpoint\n",
    "                save_dict = {\n",
    "\t\t\t\t\t\"epoch\": epoch + 1,\n",
    "\t\t\t\t\t\"state_dict\": classifier.state_dict(),\n",
    "\t\t\t\t\t\"optimizer\": optimizer.state_dict(),\n",
    "\t\t\t\t\t\"scheduler\": scheduler.state_dict(),\n",
    "\t\t\t\t\t\"best_acc\": best_acc,\n",
    "\t\t\t\t}\n",
    "                torch.save(save_dict, os.path.join(args.dump_path, \"checkpoint.pth.tar\"))\n",
    "                if (epoch+1) % args.save_freq == 0:\n",
    "                    torch.save(save_dict, os.path.join(args.dump_path, f\"checkpoint_epoch{epoch+1}.pth.tar\"))\n",
    "                if is_best:\n",
    "                    torch.save(save_dict, os.path.join(args.dump_path, \"best.pth.tar\"))\n",
    "    logger.info(\"Training of the supervised linear classifier on frozen features completed.\\n\"\n",
    "\t\t\t\t\"Top-1 test accuracy: {acc:.1f}\".format(acc=best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "58b5c6af-a333-4aa8-a9ef-bb1b4d88fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "568b4678-ebcd-4852-a906-646c8231e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 09/26/23 21:56:12 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - dump_checkpoints: ./checkpoints\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - The experiment will be stored in .\n",
      "                                     \n",
      "\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - Building data done\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - Load pretrained model with msg: None\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - classifier RegLog(\n",
      "                                       (linear): Linear(in_features=512, out_features=2, bias=True)\n",
      "                                     )\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - batchnorm parameters\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - []\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - classifier parameters\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - ['linear.weight', 'linear.bias']\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - backbone parameters\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - []\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - optimizer SGD (\n",
      "                                     Parameter Group 0\n",
      "                                         dampening: 0\n",
      "                                         differentiable: False\n",
      "                                         foreach: None\n",
      "                                         lr: 0.01\n",
      "                                         maximize: False\n",
      "                                         momentum: 0.9\n",
      "                                         nesterov: False\n",
      "                                         weight_decay: 0.0005\n",
      "                                     \n",
      "                                     Parameter Group 1\n",
      "                                         dampening: 0\n",
      "                                         differentiable: False\n",
      "                                         foreach: None\n",
      "                                         lr: 0.01\n",
      "                                         maximize: False\n",
      "                                         momentum: 0.9\n",
      "                                         nesterov: False\n",
      "                                         weight_decay: 0.0005\n",
      "                                     \n",
      "                                     Parameter Group 2\n",
      "                                         dampening: 0\n",
      "                                         differentiable: False\n",
      "                                         foreach: None\n",
      "                                         lr: 0.01\n",
      "                                         maximize: False\n",
      "                                         momentum: 0.9\n",
      "                                         nesterov: False\n",
      "                                         weight_decay: 0.0005\n",
      "                                     )\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - lr scheduler <torch.optim.lr_scheduler.MultiStepLR object at 0x7f81a606cf40>\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - cuda deterministic\n",
      "INFO - 09/26/23 21:56:12 - 0:00:00 - ============ Starting epoch 0 ... ============\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x1000 and 512x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[203], line 75\u001b[0m\n\u001b[1;32m     70\u001b[0m     cuda_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_true\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     74\u001b[0m args\u001b[38;5;241m=\u001b[39mArgs()\n\u001b[0;32m---> 75\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[200], line 127\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    123\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m============ Starting epoch \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m ... ============\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m epoch)\n\u001b[1;32m    125\u001b[0m \t\t\u001b[38;5;66;03m# set samplers\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;66;03m#train_loader.sampler.set_epoch(epoch)\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m         tr_epoch, tr_loss, tr_top1, tr_top5 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39meval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[187], line 40\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, reglog, optimizer, loader, epoch, args)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     38\u001b[0m \toutput \u001b[38;5;241m=\u001b[39m model(inp)\n\u001b[0;32m---> 40\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mreglog\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target) \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# compute the gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/OutOfDistribution/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Google Drive/Colab Notebooks/OutOfDistribution/Untitled/Out-of-distribution-generalization/src/models.py:891\u001b[0m, in \u001b[0;36mRegLog.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    889\u001b[0m \tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n\u001b[1;32m    890\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/OutOfDistribution/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/OutOfDistribution/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x1000 and 512x2)"
     ]
    }
   ],
   "source": [
    "class Args(argparse.Namespace):\n",
    "    data = './data/penn'\n",
    "    model = 'LSTM'\n",
    "    emsize = 200\n",
    "    nhid = 200\n",
    "    tags = 'some'\n",
    "    config = None\n",
    "    dump_path = '.'\n",
    "    seed = 31\n",
    "    data_path = \"../../../../ConvNetsTransferLearning/data/hymenoptera_data\"\n",
    "    #data_name = \"imagenet1k\"\n",
    "    data_name = \"hymenoptera\"\n",
    "    tf_name = \"eval\"\n",
    "    workers = 8\n",
    "    data_rate = 1\n",
    "    reweight_path = None\n",
    "    custom_eval_func = None\n",
    "\n",
    "\t#########################\n",
    "\t#### model parameters ###\n",
    "\t#########################\n",
    "    tag = None\n",
    "    arch = [\"resnet18\"]\n",
    "    pretrained = \"\"\n",
    "    skip_pool = False\n",
    "    use_bn = False\n",
    "    classifier = 'linear'\n",
    "    richway ='cat'\n",
    "    headinit = 'none'\n",
    "    headpretrained = None\n",
    "    exp_mode = 'lineareval'\n",
    "    mode = 'train'\n",
    "\t\n",
    "\t#parser.add_argument(\"--reinit_head\", default=True, type=bool_flag, help=\"\")\n",
    "    sync_bn = False\n",
    "\t\n",
    " \n",
    "\t#########################\n",
    "\t#### optim parameters ###\n",
    "\t########jvihnrbutvvthiguleudcchcjrknunbc#################\n",
    "    optimizer = 'sgd'\n",
    "    wd = 5e-4\n",
    "    wd_skip_bn = False\n",
    "\t#parser.add_argument(\"--nesterov\", default=True, type=bool_flag, help=\"nesterov momentum\")\n",
    "    nesterov = False\n",
    "    momentum = 0.9 # momentum in SGD, beta1 in adam\n",
    "    beta2 = 0.99 # beta2 in adam\n",
    "\t\n",
    "    epochs = 10\n",
    "    batch_size = 32\n",
    "    lr = 0.01\n",
    "    lr_last_layer = None\n",
    "\t\n",
    "    scheduler_type = \"step\"\n",
    "\t# for multi-step learning rate decay\n",
    "    decay_epochs = [4, 8]\n",
    "    gamma = 0.1\n",
    "\t# for cosine learning rate schedule\n",
    "    final_lr = 0\t\n",
    "    eval_freq = 1\n",
    "    save_freq = 999\n",
    "    save_init = False\n",
    "    dist_url = \"env://\"\n",
    "    world_size = -1\n",
    "    rank = 0\n",
    "\t# parser.add_argument(\"--local_rank\", default=0, type=int,\n",
    "\t#\t\t\t\t\t help=\"this argument is not used and should be ignored\")\n",
    "    debug = 'store_true'\n",
    "    gpu = None\n",
    "    cuda_deterministic = 'store_true'\n",
    "\t\n",
    "\n",
    "\n",
    "args=Args()\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "07550cf2-47c8-4142-b7a7-2b9401d4d688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args(dump_checkpoints='./checkpoints')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467876e8-5582-462d-a5f0-c9fd14a3eca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
